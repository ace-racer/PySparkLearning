# PySparkLearning
A repository to contain my Pyspark learnings

## Installing in Ubuntu
1. Download and extract Spark
    Extracted location: /home/anurag/Spark/spark-2.4.0-bin-hadoop2.7
2. Create conda environment: ```conda create --name mypyspark```
3. Activate conda environment: ```conda activate mypyspark```
4. Install pyspark: ```conda install pyspark```
